{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7yaLXlInzOpg"
      },
      "source": [
        "## Importing Necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GloCPCy5ugdm",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uj37pbOtziG-"
      },
      "source": [
        "## Opening the training files using pickle and loading them as list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FuDAOOLMuxox",
        "colab": {}
      },
      "source": [
        "with open('train_image.pkl','rb') as f:\n",
        "  X = pickle.load(f)\n",
        "\n",
        "with open('train_label.pkl','rb') as f:\n",
        "  Y = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6wyYXiN41QdE"
      },
      "source": [
        "## 'X' and 'Y' are of type \"List\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GX1RmIKwu4DI",
        "outputId": "4669fe08-b61c-4117-e4ec-f839d08c7582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(type(X))\n",
        "print(type(Y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ZXJ3u_C1XWO"
      },
      "source": [
        "## Converting the lists to Arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yuHlCflxu027",
        "outputId": "fbd669f6-bd50-4a06-8567-71aaf8573294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "print(type(X))\n",
        "print(type(Y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Ds3RFd-1d1L"
      },
      "source": [
        "## Displaying an Image data point from training DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D3QeePO7qZXA",
        "outputId": "724ecea4-59a9-4912-cdf0-d1637cff1c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "img = X[0,:].reshape(28,28)\n",
        "plt.grid(False)\n",
        "plt.imshow(img,cmap = \"gray\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fddeac1ef28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KyxhbZms3HUl"
      },
      "source": [
        "## The Classes for images are \"0\" , \"2\" , \"3\" , \"6\" and each class has 2000 instances, thus our Dataset is Balanced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f_Flz-Pv25pB",
        "outputId": "0430c7cb-60ee-48d9-cb5e-62ee823dc27b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.unique(Y,return_counts = True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 2, 3, 6]), array([2000, 2000, 2000, 2000]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gJEsVER52tI_"
      },
      "source": [
        "## Changing Label of images to continuous numbers\n",
        "\n",
        "We've to change the labels of images from [0,2,3,6] to [0,1,2,3] because if we don't change it then it'll cause problem in computing Loss for our Model and that's because we've got only 4 classes and the last class has number 6 and during computation, it checks whether **class number** is greater than the **total number of classes** or not (Here, 6 which is class number will be greater than 4 which is total number of classes). Thus, for that matter error will occur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nofmi0gjv9B1",
        "colab": {}
      },
      "source": [
        "Y[Y == 2] = 1\n",
        "Y[Y == 3] = 2\n",
        "Y[Y == 6] = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0g2pwQp7wKXr",
        "outputId": "4b305b5e-eb29-4eaa-a66b-ac9714ffab20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.unique(Y,return_counts = True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1, 2, 3]), array([2000, 2000, 2000, 2000]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zz3vnb8LwaQd",
        "outputId": "1df16e49-0b34-4dce-c1a4-b256f876fd47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 784)\n",
            "(8000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sq06LOpM56yi"
      },
      "source": [
        "We can see that our data is **NOT** randomly distributed. \n",
        "\n",
        "First 2000 images belong to class 0. \n",
        "\n",
        "From 2000 - 4000 images belong to class 1.\n",
        "\n",
        "From 4000 - 6000 images belong to class 2.\n",
        "\n",
        "From 6000 - 8000 images belong to class 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZemtbYK75jqP",
        "outputId": "ba307bc3-a147-48f9-ec05-a600a67991f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(np.unique(Y[:2000],return_counts = True))\n",
        "print(np.unique(Y[2000:4000],return_counts = True))\n",
        "print(np.unique(Y[4000:6000],return_counts = True))\n",
        "print(np.unique(Y[6000:8000],return_counts = True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0]), array([2000]))\n",
            "(array([1]), array([2000]))\n",
            "(array([2]), array([2000]))\n",
            "(array([3]), array([2000]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xuZfiiY95RoY"
      },
      "source": [
        "## We concatenate 'X' and 'Y'\n",
        "\n",
        "We concatenate 'X' and 'Y' because, we've to shuffle the final array formed to make data randomly distributed. If data is not randomly distributed then our model can give biased results, which we don't want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sDspG16gBNQ7",
        "colab": {}
      },
      "source": [
        "data = np.concatenate((X,Y[:,None]) , axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AUIFtxghBpok",
        "outputId": "16b5c667-8669-4902-8d82-f4549bbd6ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(np.unique(data[:,-1],return_counts = True))\n",
        "df = pd.DataFrame(data)\n",
        "print(np.unique(df.iloc[:,-1],return_counts = True))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1, 2, 3]), array([2000, 2000, 2000, 2000]))\n",
            "(array([0, 1, 2, 3]), array([2000, 2000, 2000, 2000]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ggFU4Bgl6-_T"
      },
      "source": [
        "## Shuffling of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KYkmQoAYBsS9",
        "outputId": "b0d58868-a33d-48f0-ffbd-82af0b57c22a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = df.sample(frac = 1).reset_index(drop = True)\n",
        "print(np.unique(df.iloc[:,-1],return_counts = True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 1, 2, 3]), array([2000, 2000, 2000, 2000]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1-MHIYLGc0dF",
        "outputId": "6c580263-85b2-4d71-821d-dade517ea0cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = df.values\n",
        "print(type(data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GzsWosa17E_B"
      },
      "source": [
        "## Checking first 100 labels of our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7jdZjJzJFxD5",
        "outputId": "5ff65196-a68d-425d-bb5f-d2683e260023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "data[:100,-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 3, 2, 3, 0, 3, 1, 0, 3, 0, 1, 1, 2, 1, 0, 3, 3, 3, 2, 1,\n",
              "       3, 0, 3, 3, 1, 3, 1, 3, 3, 3, 0, 1, 1, 2, 1, 1, 3, 2, 3, 2, 3, 3,\n",
              "       0, 1, 2, 1, 3, 3, 2, 2, 3, 0, 3, 2, 1, 1, 0, 2, 0, 0, 0, 2, 2, 2,\n",
              "       3, 1, 1, 3, 0, 2, 2, 1, 2, 2, 0, 0, 0, 2, 1, 3, 3, 0, 0, 1, 1, 2,\n",
              "       2, 2, 1, 0, 2, 3, 2, 0, 0, 3, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Znxf-cK_7L4-"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W-Xs1KfDFzYV",
        "outputId": "e6a44a00-8a3b-4990-db75-b20a48d60e9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train = data[:7000,:784] / 255.0\n",
        "Y_train = data[:7000,-1]\n",
        "\n",
        "X_val = data[7000:,:784] / 255.0\n",
        "Y_val = data[7000:,-1]\n",
        "\n",
        "print(X_train.shape, Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7000, 784) (7000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ueSbT0io7Vkf"
      },
      "source": [
        "## Checking that each Training and Validation set contain all the classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XS5VJqOQpWWt",
        "outputId": "b5408da6-7008-452b-b97d-a09db62e90bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(np.unique(Y_train))\n",
        "print(np.unique(Y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3]\n",
            "[0 1 2 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JrCEKWIP7fed"
      },
      "source": [
        "## Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_jN_Cl2NF_Ct",
        "colab": {}
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self,n_feature,hidden_01,hidden_02,hidden_03,n_output):\n",
        "        super(Net,self).__init__()\n",
        "        self.hidden_01 = torch.nn.Linear(n_feature,hidden_01)\n",
        "        self.hidden_02 = torch.nn.Linear(hidden_01,hidden_02)\n",
        "        self.hidden_03 = torch.nn.Linear(hidden_02,hidden_03)\n",
        "        self.n_output = torch.nn.Linear(hidden_03,n_output)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.hidden_01(x))\n",
        "        x = F.relu(self.hidden_02(x))\n",
        "        x = F.relu(self.hidden_03(x))\n",
        "        x = F.log_softmax(self.n_output(x))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r9eos0PO7jXe"
      },
      "source": [
        "## Our Model is a Neural Net with structure:\n",
        "\n",
        "784 --> 300 --> 100 --> 16 --> 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dwb9GVoHTo6K",
        "outputId": "5746b747-ae19-43dd-870d-979e2b8d5e95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "net = Net(n_feature = 784, hidden_01 = 300, hidden_02 = 100, hidden_03 = 16,n_output = 4)\n",
        "print(net)\n",
        "\n",
        "#optimizer = torch.optim.Adam(net.parameters(),lr=0.1)\n",
        "loss_func = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (hidden_01): Linear(in_features=784, out_features=300, bias=True)\n",
            "  (hidden_02): Linear(in_features=300, out_features=100, bias=True)\n",
            "  (hidden_03): Linear(in_features=100, out_features=16, bias=True)\n",
            "  (n_output): Linear(in_features=16, out_features=4, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LXQQiiqs9z-E"
      },
      "source": [
        "## Adam Optimizer is used with Learning Rate of 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zAKtKL1HTrz3",
        "colab": {}
      },
      "source": [
        "opt=torch.optim.Adam(net.parameters(),lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VRJNKv1w72KG"
      },
      "source": [
        "## Converting Training data to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nmg1aNTqT4hM",
        "outputId": "d262e6c1-60c4-4700-9bd5-f0176d632b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "X1 = torch.tensor(X_train).type(torch.FloatTensor)\n",
        "Y1 = torch.tensor(Y_train).type(torch.FloatTensor)\n",
        "\n",
        "print(X1.dtype)\n",
        "print(Y1.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float32\n",
            "torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WdQC9cJ477E5"
      },
      "source": [
        "## Converting Training Tensors to Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UB0TgoTMTuDF",
        "outputId": "55f847d6-d476-4fe1-d969-95b109b40264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "X_train = Variable(X1, requires_grad=True).type(torch.FloatTensor)\n",
        "Y_train = Variable(Y1, requires_grad=False).type(torch.LongTensor)\n",
        "\n",
        "print(X_train.dtype)\n",
        "print(Y_train.dtype)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float32\n",
            "torch.int64\n",
            "torch.Size([7000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "26gAO1qr8Bo6"
      },
      "source": [
        "## Training our Model on Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0DtxTpfiT09b",
        "outputId": "278f98b4-9b5e-4d8b-fab5-c66072871cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2078
        }
      },
      "source": [
        "err = []\n",
        "\n",
        "for ix in range(100):\n",
        "    \n",
        "    out = net(X_train)\n",
        "    loss = loss_func(out,Y_train)\n",
        "    \n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    \n",
        "    err.append(loss)\n",
        "    print(loss)\n",
        "    \n",
        "plt.plot(err[:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(1.3956, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3826, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3618, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3350, grad_fn=<NllLossBackward>)\n",
            "tensor(1.3010, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2611, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2188, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1739, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1281, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0831, grad_fn=<NllLossBackward>)\n",
            "tensor(1.0373, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9954, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9559, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9190, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8864, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8565, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8308, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8072, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7862, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7678, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7528, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7383, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7268, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7155, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7065, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6988, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6913, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6850, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6780, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6704, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6628, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6544, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6456, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6372, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6301, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6234, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6169, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6108, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6052, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6001, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5952, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5907, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5859, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5804, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5744, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5695, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5655, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5608, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5549, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5489, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5438, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5395, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5353, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5309, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5253, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5197, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5149, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5110, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5077, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5048, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5022, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4980, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4930, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4884, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4854, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4836, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4821, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4806, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4766, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4721, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4691, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4675, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4664, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4651, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4628, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4589, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4559, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4542, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4529, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4518, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4500, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4474, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4446, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4425, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4406, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4392, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4384, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4374, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4366, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4354, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4336, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4304, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4277, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4255, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4242, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4237, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4231, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4223, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4209, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4190, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fdde8b97f98>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIgPKdxFRHzo/wFPx7UtHzblBAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sYNbMFVW8RuO"
      },
      "source": [
        "## Printing the Least Error while training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1MFgjRctUL2o",
        "outputId": "2b9147ab-e147-4a08-e343-9538d19017e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(err[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.4190, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UQDY-tR58ZzS"
      },
      "source": [
        "## Converting Validation Data into Tensor then Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EzX03lW-erIN",
        "colab": {}
      },
      "source": [
        "X_val = torch.Tensor(X_val)\n",
        "X_val = Variable(X_val, requires_grad = True).type(torch.FloatTensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wpL8XyZv8pKC"
      },
      "source": [
        "## Testing our Model using Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dQl0Bc7LkD-A",
        "outputId": "77036878-296b-4b4e-e069-953ccfb69a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "out_val = net(X_val)\n",
        "\n",
        "print(type(out_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sA1thaN_8_8c"
      },
      "source": [
        "## Selecting the class with highest Probability, as that would be our Final Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0G134c8AkLYd",
        "outputId": "2093605f-843c-45f1-c5de-9867c23e439a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "out_final = out_val.data.numpy().argmax(axis=1)\n",
        "\n",
        "print(out_final.shape)\n",
        "print(out_final[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000,)\n",
            "[2 0 2 2 1 0 2 0 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SeNCxGsw9WSt"
      },
      "source": [
        "## Getting Accuracy on Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vXIt77Ope3Ci",
        "colab": {}
      },
      "source": [
        "acc = ((out_final == Y_val).sum()/ (X_val.shape[0])) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "syMosokg9itv"
      },
      "source": [
        "## Printing Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o_V7iQ7Te8zz",
        "outputId": "4a7609d4-c4e7-478d-8563-c4fa46a0fcd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dWN4oOtN9lEe"
      },
      "source": [
        "## Opening The Testing File in Read Mode and loading the Data in to \"test\" file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yWbGvqE6iOCP",
        "outputId": "7c15dadb-7c83-43fe-861f-0bd52e097115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('test_image.pkl','rb') as f:\n",
        "  test = pickle.load(f)\n",
        "\n",
        "type(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7zL1_DZD-PPj"
      },
      "source": [
        "## Converting list \"test\" to Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jvBJFOX5t_cS",
        "outputId": "0e64fbc4-6364-4d9e-c1dc-323d61fec1b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_dataset = np.array(test)\n",
        "print(type(test_dataset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bTKE4XAtAhCl",
        "outputId": "2a751f6c-e378-4226-dfbb-0bfec78bbc56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_dataset.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZIzmDmAx-hQi"
      },
      "source": [
        "## Normalizing Test Dataset and converting it to Tensor and then to Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oSHS6l2puPQ8",
        "outputId": "fcf11567-53d9-4bb0-d34a-a20aa77e1715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_ds = test_dataset[:,:] / 255.0\n",
        "\n",
        "test_ds = torch.Tensor(test_ds)\n",
        "test_ds = Variable(test_ds, requires_grad = True).type(torch.FloatTensor)\n",
        "\n",
        "print(type(test_ds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s8oJs-pL-n4B"
      },
      "source": [
        "## Passing our Test Dataset to Model and storing output in \"out_test\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eaKSQOvqvEyg",
        "outputId": "fa747cfe-876f-41e9-ea6e-905abaadfef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "out_test = net(test_ds)\n",
        "\n",
        "print(type(out_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xtYnFvjS-_a6"
      },
      "source": [
        "## Selecting the class with highest Probability, as that would be our Final Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xh0Pxr5IvlZQ",
        "outputId": "c4a3a500-5eed-49cc-d7a3-bdff08a6d335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "out_final = out_test.data.numpy().argmax(axis=1)\n",
        "\n",
        "print(out_final.shape)\n",
        "print(out_final[:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 3 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 2 0 0\n",
            " 3 0 0 3 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 2 2 0 0 2 2 0 0 2 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 3 0 2 2 0 0 0 0 3 3 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ujNVJEztvsXc",
        "outputId": "f756ec6e-6126-4b8d-9253-d6ea815ae3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(type(out_final))\n",
        "print(np.unique(out_final, return_counts = True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(array([0, 1, 2, 3]), array([485, 496, 514, 505]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J7r-J24nqSoX"
      },
      "source": [
        "## Converting labels back to their original form i.e., from [0,1,2,3] to [0,2,3,6]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dkgPXwRDDoUO",
        "colab": {}
      },
      "source": [
        "for ix in range(2000):\n",
        "  if out_final[ix] == 1:\n",
        "    out_final[ix] = 2\n",
        "    \n",
        "  elif out_final[ix] == 2:\n",
        "    out_final[ix] = 3\n",
        "    \n",
        "  elif out_final[ix] == 3:\n",
        "    out_final[ix] = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2_fJlfNt_d6U",
        "outputId": "8ca17965-1f32-4200-f650-01fe4e0a1afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.unique(out_final,return_counts = True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([0, 2, 3, 6]), array([485, 496, 514, 505]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pWLJIaVKB7ka",
        "outputId": "41b9d84d-1af2-49b0-f11a-2d5795221699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "print(out_final[:1000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 6 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 3 0 0\n",
            " 6 0 0 6 0 0 0 0 0 6 2 0 0 0 0 0 0 0 0 3 3 0 0 3 3 0 0 3 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 6 0 3 3 0 0 0 0 6 6 6 0 6 0 0 0 6 0 0 2 0 0\n",
            " 0 0 0 3 2 6 0 0 0 0 6 0 0 3 6 3 0 0 0 0 6 0 0 0 6 0 0 6 0 0 0 3 0 0 0 0 0\n",
            " 0 0 6 0 6 3 0 0 0 0 0 0 6 0 0 0 0 0 6 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 6 0 6 0 6 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 6 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 6 0 6 6 0 0 0 0\n",
            " 6 0 0 0 0 6 6 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 2 6 0 0 0 2\n",
            " 0 0 0 0 0 3 0 0 0 0 6 0 0 0 0 3 0 6 0 0 0 0 3 3 0 0 6 6 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 6 0 6 0 0 0 0 0 0 0 6 0 0 6 0 0 0 0 0 3 3 6 0 3 3 0 6 0 0 0 6 0 0\n",
            " 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 6 0 2 6 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 6 0 0 6 0 0 0 0 0 2 3 0 0 0 6 0 0 0 6 0 6 0 3 3 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 6 0 0 0 3 0 0 0 6 3 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 6 6 0 6 0 0 0 2 2 2 2 2 6 2 2 3 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 3 6 2 2 6 2 2 2 2 2 2 2 6 2 2 6 2 2 2 2 0 2 2 2 6\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 2 2 2 2 2 2 2 2 2 2 2 6 2 2 2 2 0 2\n",
            " 6 2 2 2 2 2 2 2 6 2 2 2 2 2 2 2 6 2 2 2 2 2 2 2 6 2 2 2 2 2 2 2 2 2 2 6 2\n",
            " 6 2 2 2 2 2 2 2 6 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 6 2 2 6 2 2 2 2 2 6\n",
            " 6 6 2 2 2 2 2 6 2 2 2 6 6 2 2 2 2 2 2 2 2 2 2 6 2 2 2 2 2 2 2 2 2 6 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 3 2 6 2 2 2 2 2 2 2 2 2 2 6 2 2 2 2 2 2 2\n",
            " 2 2 2 6 2 2 2 2 2 2 6 2 2 2 2 2 2 2 6 2 2 2 2 6 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 6 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 2 6 2 2 2 6 2 6 2 6 2 2 2 2 2 2 2\n",
            " 2 6 2 2 2 6 2 2 2 2 2 2 2 2 2 2 2 2 6 3 3 2 2 2 2 6 2 2 2 2 2 6 2 2 2 6 2\n",
            " 2 3 2 2 2 2 2 2 2 2 3 2 2 2 2 3 2 2 2 6 6 2 0 6 2 2 2 2 2 2 2 2 2 2 0 2 2\n",
            " 2 2 6 2 2 2 2 6 6 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2\n",
            " 6 2 2 2 6 2 6 2 2 2 0 2 2 2 2 6 2 2 2 6 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 2 6 2 2 2 6 6 2 2 2 2 2 2 6 2\n",
            " 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1jktEGYQEO9f",
        "outputId": "f4ecd25f-bf4e-4cf1-cbec-1bb7dcdb7b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "out_final = pd.DataFrame(out_final)\n",
        "print(type(out_final))\n",
        "print(out_final.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "(2000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SsWl-KG2rgI2",
        "colab": {}
      },
      "source": [
        "out_final.to_csv('./Ayush_Kumar_Tripathi.csv',header = True, index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7mL2ZGBAsDWa",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}